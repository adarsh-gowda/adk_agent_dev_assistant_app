Skip to main content
Documentation
Technology areas
Cross-product tools
Related sites
/
Console
Sign in
Generative AI on Vertex AI
Guides
API reference
Vertex AI Cookbook
Prompt gallery
Resources
FAQ
Contact Us
Start free
Discover
Get started
Select models
Model Garden
Try it: Test model capabilities using Playspaces
Overview of Model Garden
Use models in Model Garden
Supported models
Google Models
Overview
Gemini
Imagen
Veo
Model versions
Managed models
Model as a Service (MaaS) overview
Partner models
Open models
Model deprecations (MaaS)
Self-deployed models
Overview
Google Gemma
Llama
Use Hugging Face Models
Hex-LLM
Comprehensive guide to vLLM for Text and Multimodal LLM Serving (GPU)
xDiT
Tutorial: Deploy Llamma 3 models with SpotVM and Reservations
Model Garden notebooks
Build
Evaluate
Deploy
Administer
Go to Vertex AI documentation
Vertex AI documentation
On this page
List of Google's first-party models
List of models with open source tuning or serving recipes in Model Garden
List of partner models available in Model Garden
Starting April 29, 2025, Gemini 1.5 Pro and Gemini 1.5 Flash models are not available in projects that have no prior usage of these models, including new projects. For details, see Model versions and lifecycle.
Generative AI on Vertex AI 
Documentation
Was this helpful?
Send feedback
Models supported by Model Garden
bookmark_border

Open Source Licenses

The Model Garden might include a link to the public repository where openly available models are hosted. To confirm that you comply with the license terms, review any applicable model, dataset, or software licenses. Also confirm that you comply with any restrictions in the license (such as use-based restrictions included in the CreativeML Open RAIL-M license).

List of Google's first-party models

The following table lists the Google's first-party models that are available in Model Garden:

Model name	Modality	Description	Quickstarts
Gemini 2.5 Flash (Preview)	Language, audio, vision	Thinking model that is designed to balance price and performance.	Model card
Gemini 2.5 Pro (Preview)	Language, audio, vision	Thinking model with next generation features and improved capabilities.	Model card
Gemini 2.0 Flash	Language, audio, vision	The workhorse model for all daily tasks and features enhanced performance and supports real-time Live API.	Model card
Gemini 2.0 Flash-Lite	Language, audio, vision	The fastest and most cost efficient Flash model. It provides better quality than 1.5 for the same price and speed.	Model card
Imagen for Image Generation	Vision	Create studio-grade images at scale using text prompts. You can also use this model to upscale images.	Model card
Imagen for Editing and Customization	Vision	Edit or use few-shot learning to create studio-grade images at scale using base images and text prompts, or using reference images and text prompts.	Model card
Vertex Image Segmentation (Preview)	Vision	Use text prompts or draw scribbles to segment an image. Image segmentation lets you, for example, detect objects, remove the background of an image, or segment the foreground of an image.	Model card
Imagen for Captioning & VQA	Language	Generates a relevant description for a given image.	Model card
Embeddings for Multimodal	Vision	Generates vectors based on images, which can be used for downstream tasks like image classification and image search.	Model card
Chirp 2	Speech	Chirp 2 is a multilingual automatic speech recognition (ASR) model developed by Google that transcribes speech (speech-to-text). Compared to the first generation of Chirp models, Chirp 2 provides improved accuracy and speed, and offers new capabilities like word-level timestamps, model adaptation, and speech translation.	Model card
List of models with open source tuning or serving recipes in Model Garden

The following table lists the OSS models that support open source tuning or serving recipes in Model Garden:

Model name	Modality	Description	Quickstart
Llama 4	Language, Vision	A family of multimodal models that use the Mixture-of-Experts (MoE) architecture and early fusion.	Colab
Model card
Llama 3.3	Language	The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out).	Model card
Flux	Vision	A 12 billion parameter rectified flow transformer model that generates high-quality images from text descriptions.	Model card
Prompt Guard	Language	Guardrail LLM inputs against jailbreaking techniques and indirect injections.	Model card
Llama 3.2	Language	A collection of multilingual large language models that are pretrained and instruction-tuned generative models in 1B and 3B sizes.	Model card
Llama 3.2-Vision	Language, Vision	A collection of multimodal large language models that are pretrained and instruction-tuned image reasoning generative models in 11B and 90B sizes. These models are optimized for visual recognition, image reasoning, captioning, and answering general questions about an image.	Model card
Llama Guard 3	Language	A Llama-3.1-8B pretrained model that has been fine-tuned for content safety classification.	Model card
Qwen2	Language	Deploy Qwen2, a foundation large language model series.	Colab
Model card
Phi-3	Language	Deploy Phi-3, a foundation large language model series.	Colab
Model card
E5	Language	Deploy E5, a text embedding model series.	Colab
Model card
Instant ID	Language, Vision	Deploy Instant ID, an identity preserving, text-to-image generation model.	Colab
Model card
Llama 3	Language	Explore and build with Meta's Llama 3 models (8B, 70B, 405B) on Vertex AI.	Model card
Gemma 3	Language, Vision	Open weight models (1B text-only, 4B, 12B, 27B) that are built from the same research and technology used to create Google's Gemini models.	Model card

Gemma 2	Language	Open weight models (9B, 27B) that are built from the same research and technology used to create Google's Gemini models.	Model card

Gemma	Language	Open weight models (2B, 7B) that are built from the same research and technology used to create Google's Gemini models.	Model card

CodeGemma	Language	Open weight models (2B, 7B) designed for code generation and code completion that are built from the same research and technology used to create Google's Gemini models.	Model card

PaliGemma 2	Language, Vision	Open weight 3B, 10B and 28B models designed for image captioning tasks and visual question and answering tasks that's built from the same research and technology used to create Google's Gemini models.	Model card

PaliGemma	Language, Vision	Open weight 3B model designed for image captioning tasks and visual question and answering tasks that's built from the same research and technology used to create Google's Gemini models.	Model card

ShieldGemma 2	Language, Vision	Open weight 4B model trained on Gemma 3's 4B IT checkpoint for image safety classification across key categories that takes in images and outputs safety labels per policy.	Model card

TxGemma	Language	Open weight models (2B, 9B, 27B) designed for therapeutic development that are built upon Gemma 2.	Model card

Vicuna v1.5	Language	Deploy Vicuna v1.5 series models, which are foundation models fine-tuned from LLama2 for text generation.	Model card
NLLB	Language	Deploy nllb series models for multi-language translation.	Model card
Colab
Mistral-7B	Language	Deploy Mistral-7B, a foundational model for text generation.	Model card
BioGPT	Language	Deploy BioGPT, a text generative model for the biomedical domain.	Model card
Colab
BiomedCLIP	Language, Vision	Deploy BiomedCLIP, a multimodal foundation model for the biomedical domain.	Model card
Colab
ImageBind	Language, Vision,
Audio	Deploy ImageBind, a foundational model for multimodal embedding.	Model card
Colab
DITO	Language, Vision	Finetune and deploy DITO, a multimodal foundation model for open vocabulary object detection tasks.	Model card
Colab
OWL-ViT v2	Language, Vision	Deploy OWL-ViT v2, a multimodal foundation model for open vocabulary object detection tasks.	Model card
Colab
FaceStylizer (Mediapipe)	Vision	A generative pipeline to transform human face images to a new style.	Model card
Colab
Llama 2	Language	Finetune and deploy Meta's Llama 2 foundation models (7B, 13B, 70B) on Vertex AI.	Model card
Code Llama	Language	Deploy Meta's Code Llama foundation models (7B, 13B, 34B) on Vertex AI.	Model card
Falcon-instruct	Language	Finetune and deploy Falcon-instruct models (7B, 40B) by using PEFT.	Colab
Model card
OpenLLaMA	Language	Finetune and deploy OpenLLaMA models (3B, 7B, 13B) by using PEFT.	Colab
Model card
T5-FLAN	Language	Finetune and deploy T5-FLAN (base, small, large).	Model card (fine-tuning pipeline included)
BERT	Language	Finetune and deploy BERT by using PEFT.	Colab
Model card
BART-large-cnn	Language	Deploy BART, a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder.	Colab
Model card
RoBERTa-large	Language	Finetune and deploy RoBERTa-large by using PEFT.	Colab
Model card
XLM-RoBERTa-large	Language	Finetune and deploy XLM-RoBERTa-large (a multilingual version of RoBERTa) by using PEFT.	Colab
Model card
Stable Diffusion XL v1.0	Language, Vision	Deploy Stable Diffusion XL v1.0, which supports text-to-image generation.	Colab
Model card
Stable Diffusion XL Lightning	Language, Vision	Deploy Stable Diffusion XL Lightning, a text-to-image generation model.	Colab
Model card
Stable Diffusion v2.1	Language, Vision	Finetune and deploy Stable Diffusion v2.1 (supports text-to-image generation) by using Dreambooth.	Colab
Model card
Stable Diffusion 4x upscaler	Language, Vision	Deploy Stable Diffusion 4x upscaler, which supports text conditioned image superresolution.	Colab
Model card
InstructPix2Pix	Language, Vision	Deploy InstructPix2Pix, which supports image editing by using a text prompt.	Colab
Model card
Stable Diffusion Inpainting	Language, Vision	Finetune and deploy Stable Diffusion Inpainting, which supports inpainting a masked image by using a text prompt.	Colab
Model card
SAM	Language, Vision	Deploy Segment Anything, which supports zero-shot image segmentation.	Colab
Model card
Pic2Word Composed Image Retrieval	Language, Vision	Deploy Pic2Word, which supports multi-modal composed image retrieval.	Colab
Model card
BLIP2	Language, Vision	Deploy BLIP2, which supports image captioning and visual-question-answering.	Colab
Model card
Open-CLIP	Language, Vision	Finetune and deploy the Open-CLIP, which supports zero-shot classification.	Colab
Model card
F-VLM	Language, Vision	Deploy F-VLM, which supports open vocabulary image object detection.	Colab
Model card
tfhub/EfficientNetV2	Vision	Finetune and deploy the TensorFlow Vision implementation of the EfficientNetV2 image classification model.	Colab
Model card
EfficientNetV2 (TIMM)	Vision	Finetune and deploy the PyTorch implementation of the EfficientNetV2 image classification model.	Colab
Model card
Proprietary/EfficientNetV2	Vision	Finetune and deploy the Google proprietary checkpoint of the EfficientNetV2 image classification model.	Colab
Model card
EfficientNetLite (MediaPipe)	Vision	Finetune EfficientNetLite image classification model through MediaPipe model maker.	Colab
Model card
tfvision/vit	Vision	Finetune and deploy the TensorFlow Vision implementation of the ViT image classification model.	Colab
Model card
ViT (TIMM)	Vision	Finetune and deploy the PyTorch implementation of the ViT image classification model.	Colab
Model card
Proprietary/ViT	Vision	Finetune and deploy the Google proprietary checkpoint of the ViT image classification model.	Colab
Model card
Proprietary/MaxViT	Vision	Finetune and deploy the Google proprietary checkpoint of the MaxViT hybrid (CNN + ViT) image classification model.	Colab
Model card
ViT (JAX)	Vision	Finetune and deploy the JAX implementation of the ViT image classification model.	Colab
Model card
tfvision/SpineNet	Vision	Finetune and deploy the TensorFlow Vision implementation of the SpineNet object detection model.	Colab
Model card
Proprietary/Spinenet	Vision	Finetune and deploy the Google proprietary checkpoint of the SpineNet object detection model.	Colab
Model card
tfvision/YOLO	Vision	Finetune and deploy the TensorFlow Vision implementation of the YOLO one-stage object detection model.	Colab
Model card
Proprietary/YOLO	Vision	Finetune and deploy the Google proprietary checkpoint of the YOLO one-stage object detection model.	Colab
Model card
YOLOv8 (Keras)	Vision	Finetune and deploy the Keras implementation of the YOLOv8 model for object detection.	Colab
Model card
tfvision/YOLOv7	Vision	Finetune and deploy YOLOv7 model for object detection.	Colab
Model card
ByteTrack Video Object Tracking	Vision	Run batch prediction for video object tracking by using ByteTrack tracker.	Colab
Model card
ResNeSt (TIMM)	Vision	Finetune and deploy the PyTorch implementation of the ResNeSt image classification model.	Colab
Model card
ConvNeXt (TIMM)	Vision	Finetune and deploy ConvNeXt, a pure convolutional model for image classification inspired by the design of Vision Transformers.	Colab
Model card
CspNet (TIMM)	Vision	Finetune and deploy the CSPNet (Cross Stage Partial Network) image classification model.	Colab
Model card
Inception (TIMM)	Vision	Finetune and deploy the Inception image classification model.	Colab
Model card
DeepLabv3+ (with checkpoint)	Vision	Finetune and deploy the DeepLab-v3 Plus model for semantic image segmentation.	Colab
Model card
Faster R-CNN (Detectron2)	Vision	Finetune and deploy the Detectron2 implementation of the Faster R-CNN model for image object detection.	Colab
Model card
RetinaNet (Detectron2)	Vision	Finetune and deploy the Detectron2 implementation of the RetinaNet model for image object detection.	Colab
Model card
Mask R-CNN (Detectron2)	Vision	Finetune and deploy the Detectron2 implementation of the Mask R-CNN model for image object detection and segmentation.	Colab
Model card
ControlNet	Vision	Finetune and deploy the ControlNet text-to-image generation model.	Colab
Model card
MobileNet (TIMM)	Vision	Finetune and deploy the PyTorch implementation of the MobileNet image classification model.	Colab
Model card
MobileNetV2 (MediaPipe) Image Classification	Vision	Finetune the MobileNetV2 image classification model by using MediaPipe model maker.	Colab
Model card
MobileNetV2 (MediaPipe) Object Detection	Vision	Finetune the MobileNetV2 object detection model by using MediaPipe model maker.	Colab
Model card
MobileNet-MultiHW-AVG (MediaPipe)	Vision	Finetune the MobileNet-MultiHW-AVG object detection model by using MediaPipe model maker.	Colab
Model card
DeiT	Vision	Finetune and deploy the DeiT (Data-efficient Image Transformers) model for image classification.	Colab
Model card
BEiT	Vision	Finetune and deploy the BEiT (Bidirectional Encoder representation from Image Transformers) model for image classification.	Colab
Model card
Hand Gesture Recognition (MediaPipe)	Vision	Finetune and deploy on-device the Hand Gesture Recognition models by using MediaPipe.	Colab
Model card
Average Word Embedding Classifier (MediaPipe)	Vision	Finetune and deploy on-device the Average Word Embedding Classifier models by using MediaPipe.	Colab
Model card
MobileBERT Classifier (MediaPipe)	Vision	Finetune and deploy on-device the MobileBERT Classifier models by using MediaPipe.	Colab
Model card
MoViNet Video Clip Classification	Video	Finetune and deploy MoViNet video clip classification models.	Colab
Model card
MoViNet Video Action Recognition	Video	Finetune and deploy MoViNet models for action recognition inference.	Colab
Model card
Stable Diffusion XL LCM	Vision	Deploy this model which uses the Latent Consistency Model (LCM) to enhance text-to-image generation in Latent Diffusion Models by enabling faster and high-quality image creation with fewer steps.	Colab
Model card
LLaVA 1.5	Vision, Language	Deploy LLaVA 1.5 models.	Colab
Model card
Pytorch-ZipNeRF	Vision, Video	Train the Pytorch-ZipNeRF model which is a state-of-the-art implementation of the ZipNeRF algorithm in the Pytorch framework, designed for efficient and accurate 3D reconstruction from 2D images.	Colab
Model card
Mixtral	Language	Deploy the Mixtral model which is a Mixture of Experts (MoE) large language model (LLM) developed by Mistral AI.	Model card
Llama 2 (Quantized)	Language	Fine-tune & deploy a quantized version of Meta's Llama 2 models.	Colab
Model card
LaMa (Large Mask Inpainting)	Vision	Deploy LaMa which uses fast Fourier convolutions (FFCs), a high receptive field perceptual loss and large training masks allows for resolution-robust image inpainting.	Colab
Model card
AutoGluon	Tabular	With AutoGluon you can train and deploy high-accuracy machine learning and deep learning models for tabular data.	Colab
Model card
MaMMUT	Language, Vision	A vision-encoder and text-decoder architecture for multimodal tasks such as visual question answering, image-text retrieval, text-image retrieval, and generation of multimodal embeddings.	Colab
Model card
Whisper Large	Speech	Deploy Whisper Large, OpenAI's state-of-the-art model for automatic speech recognition (ASR).	Colab
Model card
List of partner models available in Model Garden

Some partner models are offered as managed APIs on Vertex AI Model Garden (also known as model as a service). The following table lists the models that are available from Google partners in Model Garden:

Model name	Modality	Description	Quickstart
Claude Opus 4	Language, Vision	Anthropic's most powerful model yet and the state-of-the-art coding model. Claude Opus 4 delivers sustained performance on long-running tasks that require focused effort and thousands of steps, significantly expanding what AI agents can solve.	Model card
Claude Sonnet 4	Language, Vision	Anthropic's mid-size model with superior intelligence for high-volume uses, such as coding, in-depth research, and agents.	Model card
Anthropic's Claude 3.7 Sonnet	Language, Vision	Industry-leading model for coding and powering AI agents—and the first Claude model to offer extended thinking.	Model card
Anthropic's Claude 3.5 Sonnet v2	Language, Vision	The upgraded Claude 3.5 Sonnet is a state-of-the-art model for real-world software engineering tasks and agentic capabilities. Claude 3.5 Sonnet delivers these advancements at the same price and speed as its predecessor.	Model card
Anthropic's Claude 3.5 Haiku	Language, Vision	Claude 3.5 Haiku, the next generation of Anthropic's fastest and most cost-effective model, is optimal for use cases where speed and affordability matter.	Model card
Anthropic's Claude 3 Opus	Language	A powerful AI model, with top-level performance on highly complex tasks. It can navigate open-ended prompts and sight-unseen scenarios with remarkable fluency and human-like understanding.	Model card
Anthropic's Claude 3 Haiku	Language	Anthropic's fastest vision and text model for near-instant responses to basic queries, meant for seamless AI experiences mimicking human interactions.	Model card
Anthropic's Claude 3.5 Sonnet	Language	Claude 3.5 Sonnet outperforms Anthropic's Claude 3 Opus on a wide range of Anthropic's evaluations with the speed and cost of Anthropic's mid-tier model, Claude 3 Sonnet.	Model card
DeepSeek-R1-0528 (Preview)	Language	DeepSeek's latest version of the DeepSeek R1 model.	Model card
Jamba 1.5 Large (Preview)	Language	AI21 Labs's Jamba 1.5 Large is designed for superior quality responses, high throughput, and competitive pricing compared to other models in its size class.	Model card
Jamba 1.5 Mini (Preview)	Language	AI21 Labs's Jamba 1.5 Mini is well balanced across quality, throughput, and low cost.	Model card
Llama 4 Maverick 17B-128E (GA)	Language, Vision	The largest and most capable Llama 4 model that has coding, reasoning, and image capabilities. Llama 4 Maverick 17B-128E is a multimodal model that uses the Mixture-of-Experts (MoE) architecture and early fusion.	Model card
Llama 4 Scout 17B-16E (GA)	Language, Vision	Llama 4 Scout 17B-16E delivers state-of-the-art results for its size class, outperforming previous Llama generations and other open and proprietary models on several benchmarks. Llama 4 Scout 17B-16E is a multimodal model that uses the Mixture-of-Experts (MoE) architecture and early fusion.	Model card
Llama 3.3 (GA)	Language	Llama 3.3 is a text-only 70B instruction-tuned model that provides enhanced performance relative to Llama 3.1 70B and to Llama 3.2 90B when used for text-only applications. Moreover, for some applications, Llama 3.3 70B approaches the performance of Llama 3.1 405B.	Model card
Llama 3.2 (Preview)	Language, Vision	A medium-sized 90B multimodal model that can support image reasoning, such as chart and graph analysis as well as image captioning.	Model card
Llama 3.1 (GA and Preview)	Language	

A collection of multilingual LLMs optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.

Llama 3.1 405B is generally available (GA) and priced as per dollar-per-1M-tokens. See pricing.

Llama 3.1 8B and Llama 3.1 70B are in Preview at no cost.

	Model card
Mistral OCR (25.05)	Language, Vision	Mistral OCR (25.05) is an Optical Character Recognition API for document understanding. The model comprehends each element of documents such as media, text, tables, and equations.	Model card
Mistral Small 3.1 (25.03)	Language	Mistral Small 3.1 (25.03) is the latest version of Mistral's Small model, featuring multimodal capabilities and extended context length.	Model card
Mistral Large (24.11)	Language	Mistral Large (24.11) is the next version of the Mistral Large (24.07) model now with improved reasoning and function calling capabilities.	Model card
Codestral (25.01)	Code	A cutting-edge model that's designed for code generation, including fill-in-the-middle and code completion.	Model card
Was this helpful?
Send feedback

Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.

Last updated 2025-07-07 UTC.

Why Google
Choosing Google Cloud
Trust and security
Modern Infrastructure Cloud
Multicloud
Global infrastructure
Customers and case studies
Analyst reports
Whitepapers
Products and pricing
See all products
See all solutions
Google Cloud for Startups
Google Cloud Marketplace
Google Cloud pricing
Contact sales
Support
Google Cloud Community
Support
Release Notes
System status
Resources
GitHub
Getting Started with Google Cloud
Google Cloud documentation
Code samples
Cloud Architecture Center
Training and Certification
Developer Center
Engage
Blog
Events
X (Twitter)
Google Cloud on YouTube
Google Cloud Tech on YouTube
Become a Partner
Google Cloud Affiliate Program
Press Corner
About Google
Privacy
Site terms
Google Cloud terms
Our third decade of climate action: join us
Sign up for the Google Cloud newsletter
Subscribe